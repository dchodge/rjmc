---
title: "Dengue serological analysis with mixture model"
author: "Adam Kucharski"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Serology Data Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, message=FALSE, warning=FALSE}
library(devtools)
library(rjmc)
library(lubridate)
library(patchwork)
library(tidybayes)
library(ggdist)
library(readr)
library(dplyr)
library(ggplot2)

# Using more than one core might fail on windows
if (.Platform$OS.type == "windows") {
  mc.cores <- 1
} else {
  mc.cores <- 2
}
```

## 1. Data Download and Preparation

First, we'll download and prepare the serology data:

```{r}
# Download the data
url <- "https://raw.githubusercontent.com/adamkucharski/fiji-denv3-2014/master/data/serology_inputs.csv"
serology_data <- read_csv(url)

# Calculate ELISA difference
serology_data$ELISA_diff <- serology_data$ELISA2 - serology_data$ELISA1

# Visualize the ELISA differences
ggplot(serology_data) + 
  geom_histogram(aes(ELISA_diff), bins = 30) + 
  theme_minimal() + 
  labs(x = "ELISA Difference (ELISA2 - ELISA1)", 
       y = "Frequency",
       title = "Distribution of ELISA Differences")
```

## 2. Model Definition

We'll use a mixture model that includes:
1. A normal distribution centered at 0 (representing no change)
2. One or more lognormal distributions (representing positive changes)

```{r model definition}
model <- list(
  lowerParSupport_fitted = c(-8),
  upperParSupport_fitted = c(8),
  
  namesOfParameters = c("sigma"),
  
  sampleInitPrior = function(datalist) {
    rnorm(1, 0, 1)
  },
  
  sampleInitJump = function(params, datalist) {
    # First component is always normal centered at 0
    p <- c(0.5, 0.5)
    mu <- c(0, 1)  # First mu is fixed at 0
    sigma <- c(1, 1)
    jump_new <- matrix(c(p, mu, sigma), nrow = 3, byrow = TRUE)
    jump_new
  },
  
  evaluateLogPrior = function(params, jump, datalist) {
    p <- dnorm(params[1], 0, 1, log = TRUE)
    
    p_vec <- jump[1, ]
    for(i in 1:length(p_vec) ) {
      p <- p + dunif(p_vec[i], 0, 1, log = TRUE)
    }
    mu_vec <- jump[2, ]
    # First mu is fixed at 0, others are lognormal means
    for(i in 2:length(mu_vec) ) {
      p <- p + dunif(mu_vec[i], 0, 10, log = TRUE)
    }
    sigma_vec <- jump[3, ]
    for(i in 1:length(sigma_vec) ) {
      p <- p + dunif(sigma_vec[i], 0.3, 3, log = TRUE)
    }
    N <- ncol(jump)
    p <- p + dunif(N, 1, 8)
    p
  },
  
  evaluateLogLikelihood = function(params, jump, datalist) {
    ll <- 0
    N <- ncol(jump)
    p_vec <- jump[1, ]
    mu_vec <- jump[2, ]
    sigma_vec <- jump[3, ]
    
    z <- datalist$obs
    N_data <- datalist$N_data
    sigma <- params[1]
    
    for (i in 1:N_data) {
      i_x = 0
      # First component is normal
      i_x <- i_x + p_vec[1] * dnorm(z[i], mu_vec[1], sigma_vec[1])
      # Other components are lognormal
      for (j in 2:N) {
        i_x <- i_x + p_vec[j] * dlnorm(z[i], mu_vec[j], sigma_vec[j])
      }
      ll <- ll + log(i_x)
    }
    ll
  },
  
  sampleBirthProposal = function(params, jump, i_idx, datalist) {
    p_new_sample <- runif(1, 0, 1)
    p_new <- c(jump[1, ] * (1 - p_new_sample), p_new_sample)
    mu_new_sample <- runif(1, 0, 10)  # Lognormal mean
    mu_new <- c(jump[2, ], mu_new_sample)
    sigma_new_sample <- runif(1, 0.3, 3)
    sigma_new <- c(jump[3, ], sigma_new_sample)
    jump_new <- matrix(c(p_new, mu_new, sigma_new), nrow = 3, byrow = TRUE)
    jump_new
  },
  
  sampleDeathProposal = function(params, jump, i_idx, datalist) {
    N <- ncol(jump)
    jump_remove <- jump[, i_idx]
    jump_new <- jump[, -i_idx]
    jump_new[1, ] <- c(jump_new[1, ] / (1 - jump_remove[1]))
    jump_new
  },
  
  evaluateBirthProposal = function(params, jump, i_idx, datalist) {
    N <- ncol(jump)
    log(1 / (N * dunif(jump[2, N], 0, 10)))
  },
  
  evaluateDeathProposal = function(params, jump, i_idx, datalist) {
    N <- ncol(jump)
    log((N) * dunif(jump[2, i_idx], 0, 10))
  },
  
  sampleJump = function(params, jump, i_idx, datalist) {
    N <- ncol(jump)
    jump_update <- jump[, i_idx]
    
    p_new <- min(max(jump_update[1] + rnorm(1, 0, 0.01), 0), 1)
    diff = (jump_update[1] - p_new) / (N - 1)
    p_new_vew <- jump[1, ] + diff
    p_new_vew[i_idx] <- p_new
    jump[1, ] <- p_new_vew
    
    # First mu stays at 0, others can move
    if (i_idx > 1) {
      jump[2, i_idx] <- max(jump_update[2] + rnorm(1, 0, 0.1), 0)
    }
    jump[3, i_idx] <- max(jump_update[3] + rnorm(1, 0, 0.1), 0.3)
    
    jump
  },
  
  sampleProposal = function(params, jump, datalist) {
    N <- ncol(jump)
    if (N == 2) {
      q <- c(0.0, 0.67, 1.0)
    } else if (N == 20) {
      q <- c(0.33, 1.0, 1.0)
    } else {
      q <- c(0.33, 0.67, 1.0)
    }
    q
  }
)
```

## 3. Run the Model

```{r}
# Define settings
settings <- list(
    numberCores = mc.cores,
    numberChainRuns = 4,
    iterations = 5000,  # Reduced iterations for testing
    burninPosterior = 2000,  # Reduced burnin
    thin = 5  # Reduced thinning
)

# Prepare data
data_l <- list(
    obs = serology_data$ELISA_diff,
    N_data = length(serology_data$ELISA_diff)
)

# Run the model
outputs <- rjmc_func(model, data_l, settings)
saveRDS(outputs, "serology_mixture_fit.RDS")
```

## 4. Analyze Results

### 4.1 Number of Components

```{r}
require(patchwork)
require(purrr)
require(ggplot2)

n_chain <- 4
tables_length <- get_lengths(outputs, n_chain)

if(length(tables_length) == 0) {
  stop("No components found in the posterior. Please check the model fit.")
}

df_K_post <- data.frame(
  dim = names(tables_length),
  post = as.vector(tables_length)
)

df_K_post %>% ggplot() + 
  geom_col(aes(x = dim, y = post)) + 
  theme_minimal() + 
  labs(x = "Number of mixture components", 
       y = "Posterior probability",
       title = "Posterior Distribution of Number of Components")
```

### 4.2 Component Parameters

```{r}
# Check if we have valid posterior samples
if(length(outputs$jump) == 0) {
  stop("No posterior samples found. Please check the model fit.")
}

posterior_sample <- tryCatch({
  map_df(1:4, 
    function(y) {
      if(length(outputs$jump[[y]]) == 0) return(NULL)
      map_df(1:length(outputs$jump[[y]]), 
        function(x) {
          outputs$jump[[y]][[x]] %>% t %>% 
            as.data.frame %>% 
            arrange(V2) %>% 
            mutate(n = 1:nrow(.), sample = x, chain = y) %>%
            set_names(c("p", "mu", "sigma", "n", "sample", "chain")) %>% 
            pivot_longer(-c(n, sample, chain), 
                        names_to = "parameter", 
                        values_to = "values")
        }
      )
    }
  ) %>% pivot_wider(names_from = "parameter", values_from = "values")
}, error = function(e) {
  message("Error processing posterior samples: ", e$message)
  return(NULL)
})

if(is.null(posterior_sample)) {
  stop("Could not process posterior samples. Please check the model fit.")
}

```

Plot the means
```{r}
# Plot means
p1 <- posterior_sample %>% ggplot() +    
  geom_histogram(aes(mu), color = "black", alpha = 0.7) + 
  theme_bw() + 
  labs(x = "Component Means", y = "Count",
       title = "Posterior Distribution of Component Means")

# Plot mixing proportions
p2 <- posterior_sample %>% ggplot() +    
  geom_histogram(aes(p), color = "black", alpha = 0.7) + 
  theme_bw() +
  labs(x = "Mixing Proportions", y = "Count",
       title = "Posterior Distribution of Mixing Proportions")

# Plot standard deviations
p3 <- posterior_sample %>% ggplot() +    
  geom_histogram(aes(sigma), color = "black", alpha = 0.7) + 
  theme_bw() +
  labs(x = "Standard Deviations", y = "Count",
       title = "Posterior Distribution of Standard Deviations")

p1 / p2 / p3
```

### 4.3 Fitted Distribution vs Data

```{r}
# Get the most probable number of components
mode_post <- names(sort(tables_length, decreasing = TRUE))[1]
post_process <- tryCatch({
  get_clean_posterior(outputs, mode_post, 4)
}, error = function(e) {
  message("Error getting clean posterior: ", e$message)
  return(NULL)
})

# Debug information
if(!is.null(post_process)) {
  message("Structure of post_process:")
  str(post_process)
  message("\nStructure of summary_post:")
  str(post_process$summary_post)
  message("\nNumber of rows in summary_post: ", nrow(post_process$summary_post))
  message("\nNumber of unique samples: ", length(unique(post_process$summary_post$sample)))
  message("\nNumber of unique chains: ", length(unique(post_process$summary_post$chain)))
}

# Create a data frame for plotting
x_values <- seq(min(serology_data$ELISA_diff), max(serology_data$ELISA_diff), length.out = 1000)
density_values <- rep(0, length(x_values))

# Calculate the fitted density using median values
if(!is.null(post_process) && nrow(post_process$summary_post) > 0) {
  # Get median values for each parameter
  median_params <- post_process$summary_post %>%
    group_by(order) %>%
    summarise(
      p = median(p),
      mu = median(mu),
      sigma = median(sigma)
    ) %>%
    arrange(order)
  
  for (i in 1:nrow(median_params)) {
    if(i == 1) {
      # First component is normal (noise)
      density_values <- density_values + 
        median_params$p[i] * dnorm(x_values, 
                                  median_params$mu[i], 
                                  median_params$sigma[i])
    } else {
      # Other components are lognormal (infection)
      density_values <- density_values + 
        median_params$p[i] * dlnorm(x_values, 
                                   median_params$mu[i], 
                                   median_params$sigma[i])
    }
  }
} else {
  message("Warning: No valid posterior samples found")
  density_values <- rep(NA, length(x_values))
}

# Create the plot
ggplot() +
  geom_histogram(data = serology_data, 
                 aes(x = ELISA_diff, y = ..density..), 
                 bins = 30, 
                 fill = "gray", 
                 alpha = 0.5) +
  geom_line(data = data.frame(x = x_values, y = density_values),
            aes(x = x, y = y),
            color = "red",
            linewidth = 1) +
  theme_minimal() +
  labs(x = "ELISA Difference",
       y = "Density",
       title = "Fitted Mixture Distribution vs Data",
       subtitle = paste("Using", mode_post, "components"))
```

## 5. Summary

This analysis applied a mixture model to the differences between 2013 and 2015 measurements, with:
1. A normal distribution centered at 0 (representing noise between samples)
2. One or more lognormal distributions (representing positive changes)

The results show:
1. The optimal number of components in the mixture model
2. The means and standard deviations of each component
3. The mixing proportions, indicating the relative frequency of each component
4. A comparison of the fitted distribution against the observed data

These results help identify distinct groups representing: 1) a serological rise indicative of infection and 2) no infection and potential noise in repeat assay measurements.